{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum IF3270 2023/2024\n",
    "\n",
    "Tujuan praktikum IF3270 Pembelajaran Mesin:\n",
    "1.   Peserta memahami rangkaian proses analitik data menggunakan pendekatan pembelajaran mesin. \n",
    "2.   Peserta memahami bahwa proses pengembangan model pembelajaran mesin juga ditentukan dari kualitas data, penanganan data, dan penentuan algoritma serta hyperparameter-nya; tidak cukup hanya dengan memastikan implementasi algoritma berjalan tanpa kesalahan.\n",
    "3.   Peserta mampu menginterpretasikan hasil dari evaluasi model dalam proses analitik menggunakan pendekatan pembelajaran mesin.\n",
    "\n",
    "Praktikum dilaksanakan secara berkelompok. Setiap kelompok terdiri atas 2 mahasiswa. Perhatikan bahwa terdapat berkas yang harus dikumpulkan saat keberjalanan praktikum untuk bagian A (25 April 2024, pukul 12.00 WIB) dan berkas yang dikumpulkan setelah waktu praktikum selesai untuk bagian B (25 April 2024, pukul 21.00 WIB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disediakan data yang sudah dibagi menjadi data latih (`df_train`), data validasi (`df_val`), dan data uji (`df_test`).\n",
    "\n",
    "**Bagian 1**: (batas waktu: 25 April 2024, 12.00 WIB)\n",
    "\n",
    "1. Buatlah _baseline_ dengan menggunakan model _logistic regression_.\n",
    "2. Lakukan analisis data terkait hal berikut:\n",
    "    - _duplicate value_,\n",
    "    - _missing value_,\n",
    "    - _outlier_,\n",
    "    - _balance of data_.\n",
    "3. Jelaskan rencana penanganan yang ada pada poin 2.\n",
    "4. Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan apabila dilakukan, disertai dengan alasan.\n",
    "5. Buatlah desain eksperimen dengan menentukan hal berikut:\n",
    "    - tujuan eksperimen,\n",
    "    - variabel dependen dan independen,\n",
    "    - strategi eksperimen,\n",
    "    - skema validasi.\n",
    "    \n",
    "**Bagian 2**: (batas waktu: 25 April 2024, 21.00 WIB)\n",
    "\n",
    "6. Implementasikan strategi eksperimen dan skema validasi yang telah ditentukan pada poin 5.\n",
    "7. Berdasarkan hasil prediksi yang dihasilkan, buatlah kesimpulan analisis **hasil diabetes**.\n",
    "\n",
    "---\n",
    "Catatan:\n",
    "- Jika terdapat perubahan jawaban pada poin 1—5 (contoh: perbedaan penanganan _outlier_), jelaskan pada laporan mengenai jawaban sebelum, jawaban sesudah, dan alasan pengubahan jawaban.\n",
    "- Eksperimen dapat berupa penggantian model klasifikasi, pengaturan hyperparameter, model stacking, grid search, oversampling, undersampling, dan lain sebagainya. Semakin variatif eksperimen yang dilakukan, semakin baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "`diabetes.csv` merupakan dataset yang telah dimodifikasi dari [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) sebagai kumpulan indikator individu yang diperoleh dari survei untuk kasus diabetes. Dataset ini berguna untuk melakukan prediksi diabetes sehingga suatu individu dapat diketahui memiliki risiko tinggi diabetes atau tidak. Hal ini diperoleh dari fitur-fitur yang dapat dianalisis lebih lanjut sebelum mencapai kesimpulan.\n",
    "\n",
    "Berikut adalah deskripsi singkat setiap kolom:\n",
    "\n",
    "1. **HighBP**: Memiliki tekanan darah tinggi (BP: Blood Pressure) atau tidak\n",
    "2. **HighChol**: Kolesterol tinggi atau tidak\n",
    "3. **BMI**: Besaran Body Mass Index\n",
    "4. **Smoker**: Perokok atau bukan perokok\n",
    "5. **Stroke**: Pernah mengalami struk atau tidak\n",
    "6. **HeartDiseaseorAttack**: Memiliki riwayat penyakit antara jantung koroner dan serangan jantung atau tidak sama sekali\n",
    "7. **PhysActivity**: Aktif secara fisik dalam 30 hari terakhir atau tidak\n",
    "8. **Fruits**: Mengonsumsi buah setiap hari atau tidak \n",
    "9. **Veggies**: Mengonsumsi sayur setiap hari atau tidak\n",
    "10. **HvyAlcoholConsump**: Peminum berat alkohol atau bukan \n",
    "11. **AnyHealthcare**: Memiliki perlindungan kesehatan atau tidak, contohnya memiliki asuransi kesehatan\n",
    "12. **GenHtlth**: Evaluasi mandiri terhadap kesehatan, skala 1-5 (1: Sangat baik, 2: Cukup Baik, 3: Baik, 4: Biasa saja, 5: Buruk)\n",
    "13. **MentHlth**: Jumlah hari keadaan mental buruk dalam 30 hari terakhir (skala 0-30 hari)  \n",
    "14. **PhysHlth**: Jumlah hari keadaan fisik buruk dalam 30 hari terakhir (skala 0-30 hari)\n",
    "15. **DiffWalk**: Memiliki kesulitan berjalan atau menaiki tangga\n",
    "16. **Sex**: (M) Male atau (F) Female\n",
    "17. **Age**: 13 kategori umur (1: 18-24 tahun, 9: 60-64 tahun, 13: 80 tahun ke atas)\n",
    "18. **Education**: Level edukasi skala 1-6 (1: Tidak pernah sekolah atau hanya TK, 2: SD, dst)\n",
    "19. **Income**: Skala pendapatan 1-8\n",
    "20. **Diabetes**: Apakah mengalami diabetes atau tidak (Kolom target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library di sini\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"Diabetes\")\n",
    "y = data[\"Diabetes\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "# Gunakan data validasi untuk bereksperimen dengan model\n",
    "# Gunakan data test untuk mengevaluasi model hanya di akhir eksperimen\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Deliverable_ yang akan dihasilkan adalah sebagai berikut:\n",
    "1. berkas _notebook_ dengan format nama `PraktikumIF3270_M1_NIM1_NIM2.ipynb` untuk Bagian 1;\n",
    "2. berkas _notebook_ dengan format nama `PraktikumIF3270_M2_NIM1_NIM2.ipynb` untuk Bagian 1 + Bagian 2; serta\n",
    "3. berkas laporan dengan format nama `PraktikumIF3270_NIM1_NIM2.pdf` yang mencakup hal berikut:\n",
    "    - hasil analisis data,\n",
    "    - penanganan dari hasil analisis data,\n",
    "    - justifikasi teknik-teknik yang dipilih,\n",
    "    - perubahan yang dilakukan pada jawaban poin 1—5 jika ada,\n",
    "    - desain eksperimen,\n",
    "    - hasil eksperimen,\n",
    "    - analisis dari hasil eksperimen,\n",
    "    - kesimpulan,\n",
    "    - pembagian tugas/kerja per anggota kelompok\n",
    "\n",
    "Batas waktu pengumpulan:\n",
    "- _Deliverable_ poin 1: Senin, 25 April 2023, pukul 12.00 WIB\n",
    "- _Deliverable_ poin 2: Senin, 25 April 2023, pukul 21.00 WIB\n",
    "- _Deliverable_ poin 3: Senin, 25 April 2023, pukul 21.00 WIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pembuatan Baseline Model\n",
    "\n",
    "Buatlah _baseline_ dengan menggunakan model _logistic regression_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50736 entries, 0 to 50735\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   HighBP                50736 non-null  float64\n",
      " 1   HighChol              50736 non-null  float64\n",
      " 2   BMI                   50736 non-null  float64\n",
      " 3   Smoker                50736 non-null  float64\n",
      " 4   Stroke                50736 non-null  float64\n",
      " 5   HeartDiseaseorAttack  50736 non-null  float64\n",
      " 6   PhysActivity          50736 non-null  float64\n",
      " 7   Fruits                50736 non-null  float64\n",
      " 8   Veggies               50736 non-null  float64\n",
      " 9   HvyAlcoholConsump     50736 non-null  float64\n",
      " 10  AnyHealthcare         50736 non-null  float64\n",
      " 11  GenHlth               50736 non-null  float64\n",
      " 12  MentHlth              50736 non-null  float64\n",
      " 13  PhysHlth              50736 non-null  float64\n",
      " 14  DiffWalk              50736 non-null  float64\n",
      " 15  Sex                   50736 non-null  object \n",
      " 16  Age                   50736 non-null  float64\n",
      " 17  Education             50736 non-null  float64\n",
      " 18  Income                50736 non-null  float64\n",
      " 19  Diabetes              50736 non-null  bool   \n",
      "dtypes: bool(1), float64(18), object(1)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check dataframe information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature with non-numeric data type: ['Sex', 'Diabetes']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing non-numeric data\n",
    "non_numeric_feature_names = data.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "print(f\"Feature with non-numeric data type: {non_numeric_feature_names}\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in non_numeric_feature_names:\n",
    "    df_train[feature] = label_encoder.fit_transform(df_train[feature])\n",
    "    df_val[feature] = label_encoder.fit_transform(df_val[feature])\n",
    "    df_test[feature] = label_encoder.fit_transform(df_test[feature])\n",
    "\n",
    "\n",
    "X_train = df_train.drop(columns=\"Diabetes\")\n",
    "y_train = df_train[\"Diabetes\"].copy()\n",
    "\n",
    "X_val = df_val.drop(columns=\"Diabetes\")\n",
    "y_val = df_val[\"Diabetes\"].copy()\n",
    "\n",
    "X_test = df_test.drop(columns=\"Diabetes\")\n",
    "y_test = df_test[\"Diabetes\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21865</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49180</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26462</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28564</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10746</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32470 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HighBP  HighChol   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "21865     0.0       0.0  27.0     1.0     0.0                   0.0   \n",
       "1925      0.0       0.0  27.0     0.0     0.0                   0.0   \n",
       "49180     1.0       0.0  30.0     1.0     0.0                   0.0   \n",
       "662       0.0       0.0  32.0     1.0     0.0                   0.0   \n",
       "19989     1.0       1.0  24.0     1.0     0.0                   0.0   \n",
       "...       ...       ...   ...     ...     ...                   ...   \n",
       "46248     1.0       0.0  30.0     1.0     0.0                   0.0   \n",
       "26462     0.0       0.0  28.0     0.0     0.0                   0.0   \n",
       "28564     1.0       1.0  30.0     0.0     0.0                   0.0   \n",
       "10746     1.0       0.0  37.0     1.0     0.0                   0.0   \n",
       "21537     0.0       1.0  24.0     0.0     0.0                   0.0   \n",
       "\n",
       "       PhysActivity  Fruits  Veggies  HvyAlcoholConsump  AnyHealthcare  \\\n",
       "21865           1.0     1.0      1.0                0.0            1.0   \n",
       "1925            1.0     1.0      1.0                0.0            1.0   \n",
       "49180           1.0     0.0      0.0                0.0            1.0   \n",
       "662             1.0     0.0      1.0                0.0            1.0   \n",
       "19989           1.0     1.0      1.0                0.0            1.0   \n",
       "...             ...     ...      ...                ...            ...   \n",
       "46248           1.0     1.0      1.0                0.0            1.0   \n",
       "26462           1.0     1.0      0.0                0.0            0.0   \n",
       "28564           1.0     1.0      1.0                0.0            1.0   \n",
       "10746           0.0     0.0      1.0                0.0            0.0   \n",
       "21537           1.0     1.0      1.0                0.0            1.0   \n",
       "\n",
       "       GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n",
       "21865      1.0       0.0       0.0       1.0    1  10.0        5.0     8.0   \n",
       "1925       2.0       3.0       0.0       0.0    1  12.0        6.0     8.0   \n",
       "49180      3.0       7.0       3.0       1.0    0   6.0        6.0     7.0   \n",
       "662        2.0       0.0       0.0       0.0    1   7.0        6.0     8.0   \n",
       "19989      2.0       2.0      15.0       0.0    0  11.0        6.0     8.0   \n",
       "...        ...       ...       ...       ...  ...   ...        ...     ...   \n",
       "46248      3.0       0.0       0.0       0.0    1  11.0        5.0     8.0   \n",
       "26462      1.0       0.0       0.0       0.0    1   6.0        6.0     8.0   \n",
       "28564      2.0       0.0       0.0       0.0    1   6.0        6.0     7.0   \n",
       "10746      4.0       5.0      30.0       1.0    0   9.0        4.0     6.0   \n",
       "21537      1.0       2.0       0.0       0.0    1   3.0        6.0     8.0   \n",
       "\n",
       "       Diabetes  \n",
       "21865         0  \n",
       "1925          0  \n",
       "49180         0  \n",
       "662           0  \n",
       "19989         0  \n",
       "...         ...  \n",
       "46248         1  \n",
       "26462         0  \n",
       "28564         0  \n",
       "10746         0  \n",
       "21537         0  \n",
       "\n",
       "[32470 rows x 20 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check preprocessing result\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      7027\n",
      "           1       0.56      0.15      0.24      1091\n",
      "\n",
      "    accuracy                           0.87      8118\n",
      "   macro avg       0.72      0.57      0.59      8118\n",
      "weighted avg       0.84      0.87      0.84      8118\n",
      "\n",
      "F1 Score: 0.24137931034482762\n",
      "Accuracy Score: 0.8699186991869918\n",
      "Confusion Matrix:\n",
      "[[6894  133]\n",
      " [ 923  168]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Baseline Model Training\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_val, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analisis Data\n",
    "\n",
    "Lakukan analisis data terkait hal berikut:\n",
    "- _duplicate value_,\n",
    "- _missing value_,\n",
    "- _outlier_,\n",
    "- _balance of data_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Duplicate Value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate data rows: 2329\n"
     ]
    }
   ],
   "source": [
    "duplicate = data[data.duplicated()]\n",
    "print(f\"Number of duplicate data rows: {len(duplicate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari eksekusi hasil kode bahwa terdapat cukup banyak baris pada dataset yang merupakan duplikat (memiliki nilai fitur yang sama) dari baris yang lain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Missing Value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value for each feature:\n",
      "HighBP                  0\n",
      "HighChol                0\n",
      "Income                  0\n",
      "Education               0\n",
      "Age                     0\n",
      "Sex                     0\n",
      "DiffWalk                0\n",
      "PhysHlth                0\n",
      "MentHlth                0\n",
      "GenHlth                 0\n",
      "AnyHealthcare           0\n",
      "HvyAlcoholConsump       0\n",
      "Veggies                 0\n",
      "Fruits                  0\n",
      "PhysActivity            0\n",
      "HeartDiseaseorAttack    0\n",
      "Stroke                  0\n",
      "Smoker                  0\n",
      "BMI                     0\n",
      "Diabetes                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value for each feature:\")\n",
    "print(data.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil eksekusi kode, tidak ditemukan data dengan _missing value_ pada dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Outlier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'BMI': 1979 outliers\n",
      "Values: {13.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 87.0, 89.0, 92.0, 95.0, 98.0}\n",
      "\n",
      "Feature 'MentHlth': 7308 outliers\n",
      "Values: {6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0}\n",
      "\n",
      "Feature 'PhysHlth': 8198 outliers\n",
      "Values: {8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeric_feature_names = ['BMI', 'MentHlth', 'PhysHlth']\n",
    "\n",
    "idx_to_remove = []\n",
    "for feature in numeric_feature_names:\n",
    "    Q1 = data[feature].quantile(0.25)\n",
    "    Q3 = data[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)][feature]\n",
    "\n",
    "    print(f\"Feature '{feature}': {len(outliers)} outliers\")\n",
    "    if len(outliers) != 0:\n",
    "        print(f\"Values: {set(outliers.tolist())}\")\n",
    "        idx_to_remove.extend(outliers.index.tolist())\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil eksekusi kode, ditemukan cukup banyak _outlier_ pada fitur-fitur dengan tipe data numerik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Balance of Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with diabetes = true: 6946\n",
      "Number of rows with diabetes = false: 43790\n",
      "Proportion of minority over dataset: 0.13690476190476192\n"
     ]
    }
   ],
   "source": [
    "diabetes_true = data[data[\"Diabetes\"] == True]\n",
    "diabetes_false = data[data[\"Diabetes\"] == False]\n",
    "print(f\"Number of rows with diabetes = true: {len(diabetes_true)}\")\n",
    "print(f\"Number of rows with diabetes = false: {len(diabetes_false)}\")\n",
    "print(f\"Proportion of minority over dataset: {len(diabetes_true)/len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilihat dari hasil eksekusi kode, maka dapat dikatakan bahwa dataset bersifat _imbalanced_ karena jumlah baris dengan nilai kolom target yaitu Diabetes = true hanya sekitar 13.69% dari keseluruhan data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rencana Penanganan\n",
    "\n",
    "Jelaskan rencana penanganan yang ada pada poin 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Duplicate Value_\n",
    "\n",
    "Terdapat beberapa alasan mengapa data duplikat harus ditangani:\n",
    "1. Data duplikat dapat memengaruhi proses pembelajaran atau _training_ dari suatu model karena menambahkan pola yang sama dengan data duplikat lainnya. Hal ini dapat membuat model yang dilatih lebih fokus terhadap pola-pola yang tidak representatif terhadap dataset sebenarnya.\n",
    "2. Data duplikat dapat memengaruhi proses evaluasi model, model tentunya memberikan prediksi yang sama untuk data-data duplikat. Akibatnya, hasil prediksi data duplikat memberikan bobot yang lebih besar terhadap perhitungan nilai metrik, meskipun data tersebut tidak representatif.\n",
    "3. Data duplikat meningkatkan beban komputasi saat melatih model, karena model memproses data yang sama berulang kali.\n",
    "\n",
    "Oleh karena itu, untuk menangani data duplikat, data tersebut akan dihapus dari dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Missing Value_\n",
    "\n",
    "Terdapat beberapa alasan mengapa data dengan _missing value_ harus ditangani:\n",
    "1. Data dengan _missing value_ memengaruhi nilai analisis statistik pada data seperti mean dan median dengan memberikan bias dan menyebabkan nilai tidak akurat.\n",
    "2. Data dengan _missing value_, jika dibiarkan akan menyebabkan distorsi hingga kegagalan dalam proses pembelajaran model. Hal ini karena model tidak dapat secara langsung menangani _missing value_.\n",
    "3. Data dengan _missing value_, jika ditangani dengan baik akan mampu meningkatkan efektivitas dari model yang dilatih.\n",
    "\n",
    "Jika terdapat _missing value_, maka rencana penanganannya adalah menghapus data dengan _missing value_ dari dataset. Rencana ini dipilih daripada mengisi _missing value_ dengan nilai tertentu. Hal ini demi kemudahan dan efisiensi. Selain itu, mengisi _missing value_ dengan nilai tertentu juga ditakutkan mengubah pola atau representasi dari dataset.\n",
    "Berdasarkan hasil analisis data, dataset tidak memiliki _missing value_, sehingga penanganan tidak perlu dilakukan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Outlier_\n",
    "Terdapat beberapa alasan mengapa data _outlier_ harus ditangani:\n",
    "1. Data _outlier_ dapat menyebabkan terjadinya bias terhadap nilai analisis statistik seperti mean dan standar deviasi yang menyebabkan dataset tidak tercerminkan dengan benar.\n",
    "2. Data _outlier_ dapat memengaruhi proses pembelajaran model karena memberikan bobot kepada data yang sebenarnya tidak representatif. Jika _outlier_ cukup banyak, dapat menyebabkan model tidak stabil dan prediksi tidak akurat.\n",
    "\n",
    "Oleh karena itu, untuk menangani _outlier_, data dengan _outlier_ akan dihapus dari dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Balance of Data_\n",
    "\n",
    "Terdapat beberapa alasan mengapa data yang tidak seimbang harus ditangani:\n",
    "1. _Imbalanced dataset_ dapat menyebabkan model yang dilatih cenderung untuk meminimalkan kesalahan prediksi kelas mayoritas dibandingkan dengan kelas minoritas. Hal ini menyebabkan model kurang baik atau bahkan buruk dalam memprediksi kelas minoritas.\n",
    "2. Metrik evaluasi yang digunakan bisa jadi tidak bekerja dengan baik atau tidak memberikan informasi yang tepat ketika kelas minoritas menjadi kelas yang penting untuk dapat diprediksi dengan benar.\n",
    "\n",
    "Untuk menangani _imbalanced dataset_, terdapat tiga penanganan yang dapat dilakukan.\n",
    "1. Melakukan oversampling terhadap data kelas minoritas memanfaatkan RandomOverSampler untuk menyeimbangkan jumlah data kedua kelas.\n",
    "2. Melakukan oversampling terhadap data kelas minoritas memanfaatkan SMOTE untuk menyeimbangkan jumlah data kedua kelas.\n",
    "3. Melakukan undersampling terhadap data kelas mayoritas memanfaatkan RandomUnderSampler untuk menyeimbangkan jumlah data kedua kelas.\n",
    "\n",
    "Ketiga jenis penanganan akan dilakukan untuk kemudian dicoba dilatih pada model untuk mendapatkan rencana penanganan terbaik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Teknik Encoding\n",
    "\n",
    "Jelaskan teknik _encoding_ yang digunakan terhadap data yang disediakan apabila dilakukan, disertai dengan alasan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada dataset ini, terdapat 1 fitur dengan tipe data kategorikal (object), yaitu 'Sex', yang memiliki dua nilai: F (Female) dan M (Male), dan 1 fitur dengan tipe data kategorikal (boolean), yaitu 'Diabetes', yang memiliki dua nilai: True dan False. Untuk melakukan pemrosesan data dalam model nantinya, kedua fitur ini perlu dikonversi ke format numerik. Pendekatan yang dilakukan adalah Label Encoding, yang cocok untuk data dengan sifat biner. Label Encoding memungkinkan fitur-fitur tersebut dikonversi menjadi angka, di mana setiap kategori akan diberikan label numerik tertentu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Desain Eksperimen \n",
    "Buatlah desain eksperimen dengan menentukan hal berikut: \n",
    "- tujuan eksperimen,\n",
    "- variabel dependen dan independen,\n",
    "- strategi eksperimen,\n",
    "- skema validasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tujuan Eksperimen\n",
    "Eksperimen ini bertujuan untuk mencoba berbagai parameter, metode pemrosesan, dan berbagai jenis algoritma pembelajaran untuk menghasilkan model yang paling efektif dan akurat dalam melakukan prediksi terhadap dataset Diabetes Health Indicator. Keefektifan dan keakuratan dari model akan dievaluasi dengan memanfaatkan metrik berupa nilai akurasi, f1, _confusion matrix_, serta _classification report_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabel Dependen dan Independen\n",
    "Variabel dependen pada eksperimen ini adalah variabel yang akan diprediksi, yaitu variabel Diabetes yang akan bernilai True atau False. Sedangkan, variabel independen adalah variabel yang akan dijadikan input untuk prediksi model. Variabel independen akan memengaruhi variabel dependen dan digunakan untuk memprediksi nilai variabel dependen. Dalam eksperimen ini, variabel independen adalah HighBP, HighChol, BMI, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age, Education, Income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategi Eksperimen\n",
    "\n",
    "Berikut merupakan langkah-langkah eksperimen yang akan dilakukan:\n",
    "\n",
    "##### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skema Validasi\n",
    "Skema validasi yang kami gunakan adalah holdout validation. Skema ini melibatkan pemisahan dataset menjadi dua subset terpisah: satu untuk pelatihan (training set) dan satu lagi untuk pengujian (test set). Skema ini dipilih karena memungkinkan evaluasi yang objektif dan tidak bias terhadap model yang dilatih dengan training set.\n",
    "\n",
    "Kami menggunakan metrik F1-score sebagai indikator utama performa model karena F1-score menggunakan presisi dan recall. Metrik ini sangat berguna dalam konteks data yang tidak seimbang, karena dapat menyeimbangkan kepentingan antara presisi dan kemampuan model untuk mendeteksi semua instance positif (recall).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
